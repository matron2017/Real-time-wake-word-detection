{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c96513",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "import wave\n",
    "from scipy.io.wavfile import read\n",
    "from sklearn.model_selection import train_test_split\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Sequential\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Model\n",
    "from keras.layers import  Conv1D,  GRU, Dropout, Input, Dense, Conv2D, Reshape, MaxPooling2D\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from scipy import linalg\n",
    "random.seed(111)\n",
    "fs = 16000\n",
    "Keyword_path = \"../keyword_sound\"\n",
    "Noise_path =  \"../background_sound\"\n",
    "\n",
    "Val_path_pos = \"../validation_data/positives\"\n",
    "Val_path_neg = \"../validation_data/negatives\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b89228a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spec_augment(spec: np.ndarray, num_mask=2, \n",
    "                 freq_masking_max_percentage=0.10, time_masking_max_percentage=0.2):\n",
    "\n",
    "    spec = spec.copy()\n",
    "    for i in range(num_mask):\n",
    "        all_frames_num, all_freqs_num = spec.shape\n",
    "        freq_percentage = random.uniform(0.0, freq_masking_max_percentage)\n",
    "        \n",
    "        num_freqs_to_mask = int(freq_percentage * all_freqs_num)\n",
    "        f0 = np.random.uniform(low=0.0, high=all_freqs_num - num_freqs_to_mask)\n",
    "        f0 = int(f0)\n",
    "        spec[:, f0:f0 + num_freqs_to_mask] = 0\n",
    "\n",
    "        time_percentage = random.uniform(0.0, time_masking_max_percentage)\n",
    "        \n",
    "        num_frames_to_mask = int(time_percentage * all_frames_num)\n",
    "        t0 = np.random.uniform(low=0.0, high=all_frames_num - num_frames_to_mask)\n",
    "        t0 = int(t0)\n",
    "        spec[t0:t0 + num_frames_to_mask, :] = 0\n",
    "    \n",
    "    return spec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722f6d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_data = []\n",
    "noise_data = []\n",
    "test_pos = []\n",
    "test_neg = []\n",
    "val_pos = []\n",
    "val_neg = []\n",
    "sample_rate = 16000\n",
    "keyword_data_aug = []\n",
    "noise_data_aug = []\n",
    "\n",
    "ebin_augment = []\n",
    "ebin = []\n",
    "\n",
    "keyword_audio = []\n",
    "noise_audio = []\n",
    "\n",
    "for keyword in os.listdir(Keyword_path):\n",
    "    audio, fs = librosa.load(os.path.join(Keyword_path, keyword), sr=16000)\n",
    "    keyword_audio.append(audio)\n",
    "    \n",
    "    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sample_rate, n_fft=512, hop_length=160, n_mels=48, fmax=8000)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max).T\n",
    "    mel_spec_db_norm = (mel_spec_db - np.min(mel_spec_db)) / (np.max(mel_spec_db) - np.min(mel_spec_db))\n",
    "    keyword_data.append(mel_spec_db_norm) \n",
    "    ebin.append(mel_spec_db)\n",
    "    mel_spec_db = librosa.power_to_db(spec_augment(mel_spec), ref=np.max).T\n",
    "    ebin_augment.append(mel_spec_db)\n",
    "    mel_spec_db_norm = (mel_spec_db - np.min(mel_spec_db)) / (np.max(mel_spec_db) - np.min(mel_spec_db))\n",
    "    keyword_data_aug.append(mel_spec_db_norm) \n",
    "\n",
    "\n",
    "    \n",
    "for keyword in os.listdir(Val_path_pos):\n",
    "    audio, fs = librosa.load(os.path.join(Val_path_pos, keyword), sr=16000)\n",
    "    \n",
    "    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sample_rate, n_fft=512, hop_length=160, n_mels=48, fmax=8000)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max).T\n",
    "    mel_spec_db_norm = (mel_spec_db - np.min(mel_spec_db)) / (np.max(mel_spec_db) - np.min(mel_spec_db))\n",
    "    val_pos.append(mel_spec_db_norm) \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "for noise in os.listdir(Noise_path):\n",
    "    audio, fs = librosa.load(os.path.join(Noise_path, noise), sr=16000)\n",
    "    noise_audio.append(audio)\n",
    "    \n",
    "    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sample_rate, n_fft=512, hop_length=160, n_mels=48, fmax=8000)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max).T\n",
    "    mel_spec_db_norm = (mel_spec_db - np.min(mel_spec_db)) / (np.max(mel_spec_db) - np.min(mel_spec_db))\n",
    "    noise_data.append(mel_spec_db_norm)\n",
    "    \n",
    "    mel_spec_db = librosa.power_to_db(spec_augment(mel_spec), ref=np.max).T\n",
    "    mel_spec_db_norm = (mel_spec_db - np.min(mel_spec_db)) / (np.max(mel_spec_db) - np.min(mel_spec_db))\n",
    "    noise_data_aug.append(mel_spec_db_norm) \n",
    " \n",
    "\n",
    "\n",
    "    \n",
    "for noise in os.listdir(Val_path_neg):\n",
    "    audio, fs = librosa.load(os.path.join(Val_path_neg, noise), sr=16000)\n",
    "    \n",
    "    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sample_rate, n_fft=512, hop_length=160, n_mels=48, fmax=8000)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max).T\n",
    "    mel_spec_db_norm = (mel_spec_db - np.min(mel_spec_db)) / (np.max(mel_spec_db) - np.min(mel_spec_db))\n",
    "    val_neg.append(mel_spec_db_norm) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260f0ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_shift(audio): \n",
    "    return np.roll(audio,int(sample_rate/(random.randint(2,10)))) #randint means that roll is done with freqs 1600 and 3200\n",
    "\n",
    "\n",
    "\n",
    "for audio_first in keyword_audio[::10]:\n",
    "    for audio_second in keyword_audio[::10]: \n",
    "        audio_shifted = np.add(audio_first, time_shift(audio_second)*random.uniform(0.6, 0.9))\n",
    "        \n",
    "        mel_spec = librosa.feature.melspectrogram(y=audio_shifted, sr=sample_rate, n_fft=512, hop_length=160, n_mels=48, fmax=8000)\n",
    "        mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max).T\n",
    "        mel_spec_db_norm = (mel_spec_db - np.min(mel_spec_db)) / (np.max(mel_spec_db) - np.min(mel_spec_db))\n",
    "        keyword_data.append(mel_spec_db_norm) \n",
    "        \n",
    "for audio_first in noise_audio[::10]:\n",
    "    for audio_second in noise_audio[::10]: \n",
    "        audio_shifted = np.add(audio_first, time_shift(audio_second)*random.uniform(0.6, 0.9))\n",
    "        \n",
    "        mel_spec = librosa.feature.melspectrogram(y=audio_shifted, sr=sample_rate, n_fft=512, hop_length=160, n_mels=48, fmax=8000)\n",
    "        mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max).T\n",
    "        mel_spec_db_norm = (mel_spec_db - np.min(mel_spec_db)) / (np.max(mel_spec_db) - np.min(mel_spec_db))\n",
    "        noise_data.append(mel_spec_db_norm)\n",
    "        \n",
    "\n",
    "keyword_data = keyword_data + keyword_data_aug\n",
    "noise_data = noise_data + noise_data_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883eae1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa.display\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "x = [\"\",\"0\", \"1\", \"2\", \"3\"]\n",
    "print(keyword_data[17].shape)\n",
    "img = librosa.display.specshow(keyword_data[17], x_axis='time',\n",
    "y_axis='mel', sr=16000, fmax=8000, ax=ax)\n",
    "\n",
    "fig.colorbar(img, ax=ax, format='%+2.0f dB')\n",
    "ax.set_xticklabels(x)\n",
    "ax.set(title='Augmented Mel-frequency Spectrogram')\n",
    "ax.set_xlabel(\"Time (s)\")\n",
    "ax.set_ylabel(\"Frequency (Hz)\")\n",
    "plt.savefig('augmented_mel_spec.png')\n",
    "#Let us take a look at one of the true positive and false positive samples Female voice test set. \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "x = [\"\",\"0\", \"1\", \"2\", \"3\"]\n",
    "\n",
    "img = librosa.display.specshow(noise_data[0].T, x_axis='time',\n",
    "y_axis='mel', sr=16000, fmax=8000, ax=ax)\n",
    "\n",
    "fig.colorbar(img, ax=ax, format='%+2.0f dB')\n",
    "ax.set_xticklabels(x)\n",
    "ax.set(title='Mel-frequency Spectrogram')\n",
    "ax.set_xlabel(\"Time (s)\")\n",
    "ax.set_ylabel(\"Frequency (Hz)\")\n",
    "plt.savefig('mel_spec.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216a13e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(keyword_data))\n",
    "print(np.shape(noise_data))\n",
    "print(np.shape(val_pos))\n",
    "print(np.shape(val_neg))\n",
    "\n",
    "keyword_data = np.squeeze(keyword_data)\n",
    "noise_data = np.squeeze(noise_data)\n",
    "val_pos = np.squeeze(val_pos)\n",
    "val_neg = np.squeeze(val_neg)\n",
    "\n",
    "keyword_labels = np.ones(keyword_data.shape[0])\n",
    "val_pos_labels = np.ones(val_pos.shape[0])\n",
    "\n",
    "noise_labels = 0*np.ones(noise_data.shape[0])\n",
    "val_neg_labels = 0*np.ones(val_neg.shape[0])\n",
    "\n",
    "X_train = np.concatenate((keyword_data, noise_data), axis=0)\n",
    "y_train  = np.concatenate((keyword_labels, noise_labels), axis=0)\n",
    "\n",
    "X_val = np.concatenate((val_pos, val_neg), axis=0)\n",
    "y_val = np.concatenate((val_pos_labels, val_neg_labels), axis=0)\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 2)\n",
    "y_val = tf.keras.utils.to_categorical(y_val, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f374f10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(keyword_data.shape[1])\n",
    "print(keyword_data.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df09711",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend import manual_variable_initialization \n",
    "manual_variable_initialization(True)\n",
    "\n",
    "num_units = 48\n",
    "dropout_ratio = 0.3\n",
    "checkpoint_filepath = '../keyword_model_1D_CRNN'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_filepath)\n",
    "\n",
    "my_callbacks = [tf.keras.callbacks.EarlyStopping(monitor='loss', patience=120, mode='min'),\n",
    "                tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath, save_weights_only=False, \n",
    "                monitor='val_loss', mode='min', save_best_only=True),\n",
    "]\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=(keyword_data.shape[1], keyword_data.shape[2])),\n",
    "    Conv1D(num_units,3,padding=\"same\",activation='relu',name='layer1'),\n",
    "    Dropout(dropout_ratio),\n",
    "    Conv1D(num_units,3,padding=\"same\",activation='relu',name='layer2'),\n",
    "    Dropout(dropout_ratio),\n",
    "    GRU(num_units,name='RNN_1',return_sequences=False),\n",
    "    Dense(2, activation='softmax', name='dense_a'),\n",
    "])\n",
    "\n",
    "model.compile(loss='BinaryCrossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c0d2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=2000, batch_size=32, callbacks=my_callbacks, \n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556b618d",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "model = tf.keras.Model()\n",
    "#model.load_model(latest)\n",
    "model=tf.keras.models.load_model('../keyword_model_1D_CRNN')\n",
    "\n",
    "model.evaluate(X_val, y_val, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4915a79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = history.history['val_loss']\n",
    "train_loss = history.history['loss']\n",
    "plt.plot(train_loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff2987b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Test_path_pos = \"../test_data/positives/test_female_positives\"\n",
    "Test_path_neg = \"../test_data/negatives/test_female_negatives\"\n",
    "test_pos = []\n",
    "test_neg = []\n",
    "\n",
    "for keyword in os.listdir(Test_path_pos):\n",
    "    audio, fs = librosa.load(os.path.join(Test_path_pos, keyword), sr=16000)\n",
    "    \n",
    "    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sample_rate, n_fft=512, hop_length=160, n_mels=48, fmax=8000)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max).T\n",
    "    mel_spec_db_norm = (mel_spec_db - np.min(mel_spec_db)) / (np.max(mel_spec_db) - np.min(mel_spec_db))\n",
    "    test_pos.append(mel_spec_db_norm) \n",
    "\n",
    "\n",
    "for noise in os.listdir(Test_path_neg):\n",
    "    audio, fs = librosa.load(os.path.join(Test_path_neg, noise), sr=16000)\n",
    "    \n",
    "    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sample_rate, n_fft=512, hop_length=160, n_mels=48, fmax=8000)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max).T\n",
    "    mel_spec_db_norm = (mel_spec_db - np.min(mel_spec_db)) / (np.max(mel_spec_db) - np.min(mel_spec_db))\n",
    "    test_neg.append(mel_spec_db_norm) \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cab00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(test_pos))\n",
    "print(np.shape(test_neg))\n",
    "test_pos = np.squeeze(test_pos)\n",
    "test_neg = np.squeeze(test_neg)\n",
    "test_pos_labels = np.ones(test_pos.shape[0])\n",
    "test_neg_labels = 0*np.ones(test_neg.shape[0])\n",
    "\n",
    "X_test = np.concatenate((test_pos, test_neg), axis=0)\n",
    "y_test = np.concatenate((test_pos_labels, test_neg_labels), axis=0)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ae632c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.evaluate(X_test, y_test, batch_size=32)\n",
    "hypothesis= model.predict(X_test, batch_size=32)\n",
    "y_pred = tf.keras.utils.to_categorical(hypothesis, 2)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "y_true = y_test[:, 1]\n",
    "#fpr, tpr, thresholds = precision_recall_curve(y_true, y_pred)\n",
    "\n",
    "y_pred = np.round(hypothesis[:, 1])\n",
    "CM = confusion_matrix(y_true, y_pred)\n",
    "TN = CM[0][0]\n",
    "FN = CM[1][0]\n",
    "TP = CM[1][1]\n",
    "FP = CM[0][1]\n",
    "Precision = TP/(TP+FP)\n",
    "Recall = TP/(TP+FN)\n",
    "F1_score = 2*((Precision*Recall)/(Precision+Recall))\n",
    "print(f\"true negatives: {TN}, false negatives: {FN}, true positives {TP}, false positives {FP}\")\n",
    "print(f\" Precision: {Precision}\")\n",
    "print(f\" Recall: {Recall}\")\n",
    "print(f\" F1 score: {F1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f001c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_path_pos = \"../test_data/positives/test_male_positives\"\n",
    "Test_path_neg = \"../test_data/negatives/test_male_negatives\"\n",
    "test_pos = []\n",
    "test_neg = []\n",
    "for keyword in os.listdir(Test_path_pos):\n",
    "    audio, fs = librosa.load(os.path.join(Test_path_pos, keyword), sr=16000)\n",
    "    \n",
    "    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sample_rate, n_fft=512, hop_length=160, n_mels=48, fmax=8000)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max).T\n",
    "    mel_spec_db_norm = (mel_spec_db - np.min(mel_spec_db)) / (np.max(mel_spec_db) - np.min(mel_spec_db))\n",
    "    test_pos.append(mel_spec_db_norm) \n",
    "\n",
    "for noise in os.listdir(Test_path_neg):\n",
    "    audio, fs = librosa.load(os.path.join(Test_path_neg, noise), sr=16000)\n",
    "    \n",
    "    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sample_rate, n_fft=512, hop_length=160, n_mels=48, fmax=8000)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max).T\n",
    "    mel_spec_db_norm = (mel_spec_db - np.min(mel_spec_db)) / (np.max(mel_spec_db) - np.min(mel_spec_db))\n",
    "    test_neg.append(mel_spec_db_norm) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7be08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(test_pos))\n",
    "print(np.shape(test_neg))\n",
    "test_pos = np.squeeze(test_pos)\n",
    "test_neg = np.squeeze(test_neg)\n",
    "test_pos_labels = np.ones(test_pos.shape[0])\n",
    "test_neg_labels = 0*np.ones(test_neg.shape[0])\n",
    "\n",
    "X_test = np.concatenate((test_pos, test_neg), axis=0)\n",
    "y_test = np.concatenate((test_pos_labels, test_neg_labels), axis=0)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b063aaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test, batch_size=32)\n",
    "hypothesis= model.predict(X_test, batch_size=32)\n",
    "y_pred = tf.keras.utils.to_categorical(hypothesis, 2)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "y_true = y_test[:, 1]\n",
    "\n",
    "#fpr, tpr, thresholds = precision_recall_curve(y_true, y_pred)\n",
    "\n",
    "\n",
    "y_pred = np.round(hypothesis[:, 1])\n",
    "CM = confusion_matrix(y_true, y_pred)\n",
    "TN = CM[0][0]\n",
    "FN = CM[1][0]\n",
    "TP = CM[1][1]\n",
    "FP = CM[0][1]\n",
    "Precision = TP/(TP+FP)\n",
    "Recall = TP/(TP+FN)\n",
    "F1_score = 2*((Precision*Recall)/(Precision+Recall))\n",
    "print(f\"true negatives: {TN}, false negatives: {FN}, true positives {TP}, false positives {FP}\")\n",
    "print(f\" Precision: {Precision}\")\n",
    "print(f\" Recall: {Recall}\")\n",
    "print(f\" F1 score: {F1_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 11:38:47) \n[GCC 7.5.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "d24800f016d62d39d05c84f087c423062fe9fe39fe06d695a6b78b39a245f41d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
