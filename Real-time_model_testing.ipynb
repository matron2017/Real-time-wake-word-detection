{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "import wave\n",
    "from scipy.io.wavfile import read\n",
    "from sklearn.model_selection import train_test_split\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Sequential\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Model\n",
    "from keras.layers import  Conv1D,  GRU, Dropout, Input, Dense, Conv2D, Reshape, MaxPooling2D\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from scipy import linalg\n",
    "sample_rate = 16000\n",
    "seconds = 3\n",
    "case=0\n",
    "model = tf.keras.Model()\n",
    "model=tf.keras.models.load_model('../keyword_model_1D_CRNN')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording = sd.rec(int(seconds * fs), samplerate=sample_rate, channels=1)\n",
    "sd.wait()\n",
    "first_audio = np.squeeze(recording)\n",
    "\n",
    "long_audio=first_audio\n",
    "while True:\n",
    "    if case == 150:\n",
    "        break\n",
    "    case+= 1\n",
    "    print(\"Say Now: \")\n",
    "    recording = sd.rec(int(1 * fs), samplerate=fs, channels=1)\n",
    "    sd.wait()\n",
    "    \n",
    "    audio = np.squeeze(recording)\n",
    "    long_audio = np.delete(long_audio , [index for index in range(int(np.shape(audio)[0]))] )\n",
    "    long_audio = np.hstack((long_audio, audio))\n",
    "    mel_spec = librosa.feature.melspectrogram(y=long_audio, sr=sample_rate, n_fft=512, hop_length=160, n_mels=48, fmax=8000)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max).T\n",
    "    mel_spec_db_norm = (mel_spec_db - np.min(mel_spec_db)) / (np.max(mel_spec_db) - np.min(mel_spec_db))\n",
    "\n",
    "    prediction = model.predict(np.expand_dims(mel_spec_db_norm, axis=0), batch_size=32)\n",
    "    print(prediction)\n",
    "    if prediction[:, 1] > 0.50:\n",
    "        print(f\"Wake Word Detected for ({case})\")\n",
    "        print(\"Confidence:\", prediction[:, 1])\n",
    "        \n",
    "    \n",
    "    else:\n",
    "        print(f\"Wake Word NOT Detected\")\n",
    "        print(\"Confidence:\", prediction[:, 0])\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "avatarenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 11:38:47) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d24800f016d62d39d05c84f087c423062fe9fe39fe06d695a6b78b39a245f41d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
