# Real-time-wake-word-detection
In this project, question segmentation is made by detecting wake-words in 3-second segments in real-time. Every 1 second, 3 past seconds are classified as a positive or negative sample of our wake-word. This is done by removing from the old 3-second sample the first 1 second and adding to the end the newly recorded 1 second of audio. This means the first 3 seconds need to be recorded to start classifying. The classification is done by making 3-second audio intervals into Mel spectrograms. These are given to CRNN as inputs and are then classified as 1 (wake-word) or 0 (noise).  When a wake-word is detected, a speech-to-text module of the avatar is activated, which means it listens for a question. Avatar will be recording audio until the wake-word is spoken. It will only keep in memory the last 3 seconds of audio.

The implementation was done in Python. The detection model was implemented using the machine learning library TensorFlow and Mel spectrograms were created using the audio processing library Librosa. Mel spectrograms were produced with a sampling rate of 16000 Hz, hop length of 160, length of the FFT window as 512, and window length of 48.
